# Self-view Grounding Given a Narrated 360° Video

[Shih-Han Chou](https://shihhanchou.github.io/), [Yi-Chun Chen](https://chenyichun.github.io/), [Kuo-Hao Zeng](https://kuohaozeng.github.io/), [Hou-Ning Hu](https://eborboihuc.github.io/), [Jianlong Fu](https://www.microsoft.com/en-us/research/people/jianf/), [Min Sun](http://aliensunmin.github.io/)

Association for the Advancement of Artificial Intelligence (AAAI) ,2018  
Official Implementation of AAAI 2018 paper "Self-view Grounding Given a Narrated 360° Video" in Pytorch.

Project page: [http://aliensunmin.github.io/project/360grounding/](http://aliensunmin.github.io/project/360grounding/)  
Paper: [ArXiv](https://arxiv.org/abs/1711.08664)

# Prerequisites
* Linux  
* NVIDIA GPU + CUDA 7.0 + CuDNNv5.1  
* Python 2.7 with numpy  
* Pytorch 0.3.0  

# Getting Started
* Clone this repo
```
git clone https://github.com/ShihHanChou/360grounding.git
```
* Download our [dataset](https://github.com/ShihHanChou/360grounding/blob/master/README.md#dataset)

# Dataset
